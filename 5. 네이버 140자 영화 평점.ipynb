{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. iframe을 통해서 페이지를 표시하고 있다.\n",
    "2. 요청할 페이지를 소스보기 하면 소스에 데이터가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import time\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163608 수집 시작\n",
      "1 / 5\n",
      "2 / 5\n",
      "3 / 5\n",
      "4 / 5\n",
      "5 / 5\n",
      "132623 수집 시작\n",
      "1 / 5\n",
      "2 / 5\n",
      "3 / 5\n",
      "4 / 5\n",
      "5 / 5\n",
      "수집 완료\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페이지를 요청하여 bs4객체를 반환하는 함수\n",
    "def requestPage(url) :\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 정보를 가져온다.\n",
    "def getData(soup) :\n",
    "    # li 태그들을 가져온다.\n",
    "    li_list = soup.select('div.score_result > ul > li')\n",
    "    # print(li_list)\n",
    "    \n",
    "    reple_list = []\n",
    "    score_list = []\n",
    "    \n",
    "    for li_tag in li_list :\n",
    "        # 평점을 가져온다.\n",
    "        star_score_tag = li_tag.select('div.star_score > em')\n",
    "        star_score = star_score_tag[0].text.strip()\n",
    "        # print(star_score_tag[0].prettify())\n",
    "        # print(star_score)\n",
    "        # 140자 평을 가져온다.\n",
    "        score_reple_tag = li_tag.select('div.score_reple > p')\n",
    "        score_reple = score_reple_tag[0].text.strip()\n",
    "        # print(score_reple)\n",
    "        \n",
    "        #print(star_score)\n",
    "        #print(score_reple)\n",
    "        \n",
    "        score_list.append(star_score)\n",
    "        reple_list.append(score_reple)\n",
    "        \n",
    "    return score_list, reple_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 페이지 개수를 반환하는 함수\n",
    "def getPageCnt(movie_code) :\n",
    "    # 접속할 페이지의 주소\n",
    "    url = f'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code={movie_code}&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=1'\n",
    "    # 요청한다.\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    # class가 score_total인 div를 가져온다.\n",
    "    score_total_tag = soup.select('div.score_total > strong.total > em')[0]\n",
    "    total_reple_cnt = score_total_tag.text.strip()\n",
    "    # print(total_reple_cnt)\n",
    "    # 계산한다.\n",
    "    total_reple_cnt = total_reple_cnt.replace(',', '')\n",
    "    total_page_cnt = int(total_reple_cnt) // 10\n",
    "    if int(total_reple_cnt) % 10 > 0 :\n",
    "        total_page_cnt += 1\n",
    "        \n",
    "    return total_page_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영화 코드를 가져오는 함수\n",
    "def getMovieCode() :\n",
    "    # 영화 코드를 담을 리스트\n",
    "    movie_code_list = []\n",
    "    \n",
    "    # 접속할 페이지의 주소\n",
    "    url = 'https://movie.naver.com/movie/running/current.nhn?order=reserve'\n",
    "    # 요청한다.\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    li_list = soup.select('ul.lst_detail_t1 > li')\n",
    "    for li_tag in li_list :\n",
    "        # a 태그를 가져온다.\n",
    "        a_tag = li_tag.select('div.thumb > a')[0]\n",
    "        # a 태그의 href 속성값을 가져온다.\n",
    "        href = a_tag.attrs['href']\n",
    "        # print(href)\n",
    "        # 영화 코드 값을 가져온다.\n",
    "        str1 = href.strip()\n",
    "        str2 = str1.split('=')\n",
    "        movie_code = str2[1]\n",
    "        # print(movie_code)\n",
    "        movie_code_list.append(movie_code)\n",
    "        \n",
    "    return movie_code_list\n",
    "        \n",
    "#getMovieCode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 저장인지 아는지를 구분하기 위한 변수\n",
    "chk = False\n",
    "\n",
    "# 가져올 영화 코드가 있는 리스트\n",
    "# movie_list = [156464, 109906]\n",
    "movie_list = getMovieCode()\n",
    "\n",
    "# movie_list = movie_list[:2]\n",
    "\n",
    "for movie_code in movie_list :\n",
    "    \n",
    "    print(f'{movie_code} 수집 시작')\n",
    "    \n",
    "    # 페이지 수를 가져온다.\n",
    "    total_page_cnt = getPageCnt(movie_code)\n",
    "\n",
    "    # total_page_cnt = 5\n",
    "\n",
    "\n",
    "    for idx in range(total_page_cnt) :\n",
    "        print(f'{idx + 1} / {total_page_cnt}')\n",
    "        time.sleep(1)\n",
    "        # 접속할 페이지의 주소\n",
    "        url = f'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code={movie_code}&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page={idx + 1}'\n",
    "        # 요청한다.\n",
    "        soup = requestPage(url)\n",
    "        # print(soup)\n",
    "        # 데이터를 가져온다.\n",
    "        score_list, reple_list = getData(soup)\n",
    "        # print(score_list)\n",
    "        # print(reple_list)\n",
    "        # print('-----------------')\n",
    "        # DataFrame을 생성한다.\n",
    "        # 두 리스트를 합친다.\n",
    "        total_list = zip(reple_list, score_list)\n",
    "        df = pandas.DataFrame(list(total_list))\n",
    "\n",
    "        if chk == False :\n",
    "            chk = True\n",
    "            df.columns = ['text', 'star']\n",
    "            df.to_csv('naver_star_data.csv', index=False, encoding='utf-8-sig')\n",
    "        else :\n",
    "            df.to_csv('naver_star_data.csv', index=False, encoding='utf-8-sig', mode='a', header=False)\n",
    "\n",
    "print('수집 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
